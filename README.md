# Ollama IA Chat Interface

Une interface de chat moderne qui se connecte √† Ollama pour des conversations aliment√©es par l'IA.

## ‚ö†Ô∏è Pr√©requis Important

Cette application n√©cessite :

1. Ollama install√© sur votre machine
2. Le mod√®le llama3.2 sp√©cifiquement (autres mod√®les non support√©s)
3. Le serveur Ollama d√©marr√© avec la commande :
   ```bash
   ollama serve
   ```

## Caract√©ristiques

- üé® Interface utilisateur moderne avec th√®me sombre
- üí¨ Chat en temps r√©el
- ‚ú® Support du Markdown
- üîÑ Animations de chargement
- ‚å®Ô∏è Raccourcis clavier (Entr√©e pour envoyer)
- üì± Design responsive

## Stack Technique

- Vue 3 avec TypeScript
- Tailwind CSS
- Marked.js pour le rendu Markdown
- Highlight.js pour la coloration syntaxique
- Int√©gration API Ollama

## Configuration

1. Installez Ollama depuis le site officiel
2. Installez le mod√®le llama3.2 :
   ```bash
   ollama pull llama3.2
   ```
3. D√©marrez le serveur Ollama :
   ```bash
   ollama serve
   ```
4. Le serveur doit √™tre accessible sur `localhost:11434`

## Utilisation

- Assurez-vous que le serveur Ollama est en cours d'ex√©cution
- Tapez votre message dans la zone de texte
- Envoyez avec le bouton ou la touche Entr√©e
- Les r√©ponses sont format√©es automatiquement avec support Markdown
- Les messages d'erreur s'affichent si le serveur n'est pas accessible

## Limitations

- Fonctionne exclusivement avec le mod√®le llama3.2
- N√©cessite une connexion locale au serveur Ollama
- Le serveur doit √™tre d√©marr√© avant l'utilisation de l'interface

## Interface

- Zone de chat avec historique des messages
- Distinction visuelle entre messages utilisateur et assistant
- Indicateur de chargement pendant le traitement
- Zone de saisie avec bouton d'envoi
- Support du formatage Markdown dans les r√©ponses
